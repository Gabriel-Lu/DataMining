# DataMinig0701
## 利用WEKA读取数据，用KNN算法训练，使得结果准确率达到100%步骤记录
   -     CMD输入java -jar weka.jar启动weka软件
   -     Preprocess中，在Filter中选择unsupervised 的Normalize，点击apply，进行归一化处理，使得几个指标的权重一样
   -     Classify中，在Classifier中选择lazy-IBK(K邻近函数），右键选择属性列。
        -     在nearsetNeighbourSearchAlgorithm中可以选择距离的种类，默认的是linearNNSearch（欧氏距离），设置KNN（K的值）
        -     采用交叉验证的方式选取K值，设置成我们向考虑最大的K值。并设置cross-validate(交叉验证）为true.
        -    K折交叉验证(K-fold cross validation)指的是把训练数据D 分为 K份，用其中的(K-1)份训练模型，把剩余的1份数据用于评估模型的质量。将这个过程在K份数据上依次循环，并对得到的K个评估结果进行合并，如求平均或投票。
   -     点击start运行
   -     查看classifier output中的结果
        -     detailed accuracy by class中各个字符的含义
             -     (TP) rate:True positive，被正确分类为class x的比率。
             -     (FP) rate:False positive，被错误分类为class x的比率。
             -     Precision：类型为class x的instances被正确分类为class x的比率。
             -     特别的，如果要在UCI下载数据文件，由于UCI文件的格式是.data,直接读的话WEKA无法读取。因此我们需要改.data文件后缀名为.csv,再在WEKA启动栏的tool打开文件并保存为arff后缀的文件。再打开即可。（可能出现的错误：会丢失第一行的数据，因此我们需要在arff文件中加上属性并补充第一行的属性值）
   -     Expolorer中Test options 评价模型效果的方法，有四个选项。 
              -     a）Use training set：使用训练集，即训练集和测试集使用同一份数据，一般不使用这种方法。这种方法的precision也不总是100%
              -     b）Supplied test set：设置测试集，可以使用本地文件或者url，测试文件的格式需要跟训练文件格式一致。 
              -     c）Cross-validation：交叉验证，很常见的验证方法。N-folds cross-validation是指，将训练集分为N份，使用N-1份做训练，使用1份做测试，如此循环N次，最后整体计算结果。 常常设置N为5或者10.
             -     d）Percentage split：按照一定比例，将训练集分为两份，一份做训练，一份做测试。常常是80%和20%；在这些验证方法的下面，有一个More options选项，可以设置一些模型输出，模型验证的参数。，还可以在random seed中调节随机种子的值，若不调节，则每次的伪随机种子都是一样的。
   -     Overfitting:过度拟合问题，广泛存在于机器学习中。训练出来的分类规则过度细致繁琐，比如每个规则都对应了一个将要预报的天气，导致实际使用效果并不好。solution:划分整个数据集为train,test,validation.train和test用于选择机器学习的方法，validation用于验证方法。
